{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copia de Keras Flowers transfer learning (solution).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianaguu/IA/blob/master/Copia_de_Keras_Flowers_transfer_learning_(solution).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VQh6RAPVMAKm"
      },
      "source": [
        "Training on GPU will be fine for transfer learning as it is not a very demanding process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "89B27-TGiDNB"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9u3d4Z7uQsmp",
        "outputId": "9a97c3ce-31a0-479f-b762-9033b0a71a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import os, sys, math\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "if 'google.colab' in sys.modules: # Colab-only Tensorflow version selector\n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Tensorflow version 1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w9S3uKC_iXY5"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M3G-2aUBQJ-H",
        "outputId": "c6d9e700-4170-455c-9adb-2746f8b04191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "MPkvHdAYNt9J",
        "colab": {}
      },
      "source": [
        "#@title display utilities [RUN ME]\n",
        "\n",
        "def dataset_to_numpy_util(dataset, N):\n",
        "  dataset = dataset.batch(N)\n",
        "  \n",
        "  for images, labels in dataset:\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "    break;\n",
        "\n",
        "  return numpy_images, numpy_labels\n",
        "\n",
        "def title_from_label_and_target(label, correct_label):\n",
        "  correct = (label == correct_label)\n",
        "  return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n",
        "                              CLASSES[correct_label] if not correct else ''), correct\n",
        "\n",
        "def display_one_flower(image, title, subplot, red=False):\n",
        "    plt.subplot(subplot)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    plt.title(title, fontsize=16, color='red' if red else 'black')\n",
        "    return subplot+1\n",
        "  \n",
        "def display_9_images_from_dataset(dataset):\n",
        "  subplot=331\n",
        "  plt.figure(figsize=(13,13))\n",
        "  images, labels = dataset_to_numpy_util(dataset, 9)\n",
        "  for i, image in enumerate(images):\n",
        "    title = CLASSES[labels[i]]\n",
        "    subplot = display_one_flower(image, title, subplot)\n",
        "    if i >= 8:\n",
        "      break;\n",
        "              \n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "  \n",
        "def display_9_images_with_predictions(images, predictions, labels):\n",
        "  subplot=331\n",
        "  plt.figure(figsize=(13,13))\n",
        "  classes = np.argmax(predictions, axis=-1)\n",
        "  for i, image in enumerate(images):\n",
        "    title, correct = title_from_label_and_target(classes[i], labels[i])\n",
        "    subplot = display_one_flower(image, title, subplot, not correct)\n",
        "    if i >= 8:\n",
        "      break;\n",
        "              \n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "  \n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  if subplot%10==1: # set up the subplots on the first call\n",
        "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "    plt.tight_layout()\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.set_facecolor('#F8F8F8')\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['train', 'valid.'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kvPXiovhi3ZZ"
      },
      "source": [
        "## Read images and labels from TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtAVr-4CP1rp",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 80, 80\n",
        "IMAGE_SIZE = [80, 80]\n",
        "train_data_dir = '/content/drive/My Drive/Colab Notebooks/data/train'\n",
        "validation_data_dir = '/content/drive/My Drive/Colab Notebooks/data/validation'\n",
        "nb_train_samples = 560\n",
        "nb_validation_samples = 120\n",
        "epochs = 200\n",
        "batch_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yCDq52zgRHtH"
      },
      "source": [
        "## training and validation datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALtRUlxhw8Vt"
      },
      "source": [
        "## Model [WORK WAS REQUIRED HERE]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XLJNVGwHUDy1",
        "outputId": "07964481-a64e-42fa-fac8-2c93a2ccf824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
        "#pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "### QUESTION 1.\n",
        "model = tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 3, 3, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 36866     \n",
            "=================================================================\n",
            "Total params: 23,624,578\n",
            "Trainable params: 36,866\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMfenMQcxAAb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M-ID7vP5mIKs",
        "outputId": "36ed99ca-ea46-4be5-90ff-8e3a8d22b7dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator( rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen  = ImageDataGenerator( rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( train_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='sparse')\n",
        "validation_generator = test_datagen.flow_from_directory( validation_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='sparse')\n",
        "model.fit( train_generator, steps_per_epoch=nb_train_samples // batch_size, epochs=epochs,  validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "#history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,validation_data=validation_generator, validation_steps=nb_validation_samples)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 560 images belonging to 2 classes.\n",
            "Found 120 images belonging to 2 classes.\n",
            "Epoch 1/200\n",
            "10/11 [==========================>...] - ETA: 9s - loss: 1.1466 - acc: 0.6391 Epoch 1/200\n",
            "11/11 [==============================] - 124s 11s/step - loss: 1.1532 - acc: 0.6451 - val_loss: 1.1576 - val_acc: 0.4700\n",
            "Epoch 2/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.7445 - acc: 0.8109Epoch 1/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.7202 - acc: 0.8176 - val_loss: 0.7839 - val_acc: 0.4700\n",
            "Epoch 3/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3876 - acc: 0.8826Epoch 1/200\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.3735 - acc: 0.8863 - val_loss: 0.7640 - val_acc: 0.4700\n",
            "Epoch 4/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1807 - acc: 0.9196Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.1761 - acc: 0.9216 - val_loss: 0.6877 - val_acc: 0.4900\n",
            "Epoch 5/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2246 - acc: 0.9174Epoch 1/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.2345 - acc: 0.9157 - val_loss: 0.8019 - val_acc: 0.5300\n",
            "Epoch 6/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2386 - acc: 0.9260Epoch 1/200\n",
            "11/11 [==============================] - 2s 181ms/step - loss: 0.2758 - acc: 0.9164 - val_loss: 0.7437 - val_acc: 0.5300\n",
            "Epoch 7/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1441 - acc: 0.9405Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1399 - acc: 0.9404 - val_loss: 0.8231 - val_acc: 0.5300\n",
            "Epoch 8/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1200 - acc: 0.9620Epoch 1/200\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.1188 - acc: 0.9600 - val_loss: 0.8099 - val_acc: 0.5300\n",
            "Epoch 9/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1383 - acc: 0.9435Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.1340 - acc: 0.9471 - val_loss: 0.9034 - val_acc: 0.5300\n",
            "Epoch 10/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1165 - acc: 0.9543Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.1258 - acc: 0.9549 - val_loss: 1.0523 - val_acc: 0.5300\n",
            "Epoch 11/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1013 - acc: 0.9630Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0974 - acc: 0.9647 - val_loss: 1.4515 - val_acc: 0.5300\n",
            "Epoch 12/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1373 - acc: 0.9587Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1470 - acc: 0.9549 - val_loss: 0.9348 - val_acc: 0.5300\n",
            "Epoch 13/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1718 - acc: 0.9457Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.1765 - acc: 0.9451 - val_loss: 1.4767 - val_acc: 0.5300\n",
            "Epoch 14/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1551 - acc: 0.9435Epoch 1/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.1524 - acc: 0.9471 - val_loss: 1.2574 - val_acc: 0.5300\n",
            "Epoch 15/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1621 - acc: 0.9580Epoch 1/200\n",
            "11/11 [==============================] - 2s 182ms/step - loss: 0.1501 - acc: 0.9618 - val_loss: 1.2425 - val_acc: 0.5300\n",
            "Epoch 16/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1610 - acc: 0.9500Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1575 - acc: 0.9511 - val_loss: 1.5538 - val_acc: 0.5300\n",
            "Epoch 17/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1384 - acc: 0.9587Epoch 1/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.1274 - acc: 0.9608 - val_loss: 1.8247 - val_acc: 0.5300\n",
            "Epoch 18/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0818 - acc: 0.9600Epoch 1/200\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.0761 - acc: 0.9636 - val_loss: 2.3486 - val_acc: 0.5300\n",
            "Epoch 19/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0968 - acc: 0.9630Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0942 - acc: 0.9647 - val_loss: 1.8955 - val_acc: 0.5300\n",
            "Epoch 20/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0894 - acc: 0.9652Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0837 - acc: 0.9686 - val_loss: 1.6155 - val_acc: 0.5300\n",
            "Epoch 21/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0759 - acc: 0.9717Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0699 - acc: 0.9745 - val_loss: 1.8716 - val_acc: 0.5300\n",
            "Epoch 22/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2004 - acc: 0.9543Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1842 - acc: 0.9569 - val_loss: 1.3480 - val_acc: 0.5300\n",
            "Epoch 23/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0533 - acc: 0.9783Epoch 1/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.0520 - acc: 0.9765 - val_loss: 1.7005 - val_acc: 0.5300\n",
            "Epoch 24/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1312 - acc: 0.9630Epoch 1/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.1284 - acc: 0.9647 - val_loss: 1.5199 - val_acc: 0.5300\n",
            "Epoch 25/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.1426 - acc: 0.9556Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1241 - acc: 0.9588 - val_loss: 1.2875 - val_acc: 0.5300\n",
            "Epoch 26/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0943 - acc: 0.9700Epoch 1/200\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0863 - acc: 0.9706 - val_loss: 2.0950 - val_acc: 0.5300\n",
            "Epoch 27/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0976 - acc: 0.9761Epoch 1/200\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0962 - acc: 0.9745 - val_loss: 1.4385 - val_acc: 0.5300\n",
            "Epoch 28/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1283 - acc: 0.9660Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1214 - acc: 0.9667 - val_loss: 2.0046 - val_acc: 0.5300\n",
            "Epoch 29/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1114 - acc: 0.9740Epoch 1/200\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.1094 - acc: 0.9727 - val_loss: 1.3260 - val_acc: 0.5300\n",
            "Epoch 30/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1375 - acc: 0.9696Epoch 1/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.1264 - acc: 0.9702 - val_loss: 1.1141 - val_acc: 0.5300\n",
            "Epoch 31/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1271 - acc: 0.9720Epoch 1/200\n",
            "11/11 [==============================] - 2s 183ms/step - loss: 0.1229 - acc: 0.9727 - val_loss: 1.3985 - val_acc: 0.5300\n",
            "Epoch 32/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0774 - acc: 0.9761Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0721 - acc: 0.9766 - val_loss: 0.7907 - val_acc: 0.5200\n",
            "Epoch 33/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0932 - acc: 0.9680Epoch 1/200\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.0855 - acc: 0.9709 - val_loss: 1.3860 - val_acc: 0.5300\n",
            "Epoch 34/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0715 - acc: 0.9739Epoch 1/200\n",
            "11/11 [==============================] - 2s 175ms/step - loss: 0.0696 - acc: 0.9745 - val_loss: 0.9611 - val_acc: 0.5300\n",
            "Epoch 35/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1374 - acc: 0.9696Epoch 1/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.1252 - acc: 0.9706 - val_loss: 1.3153 - val_acc: 0.5300\n",
            "Epoch 36/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1593 - acc: 0.9652Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1597 - acc: 0.9667 - val_loss: 0.9376 - val_acc: 0.5300\n",
            "Epoch 37/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1353 - acc: 0.9696Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1302 - acc: 0.9686 - val_loss: 1.7580 - val_acc: 0.5300\n",
            "Epoch 38/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0991 - acc: 0.9674Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0908 - acc: 0.9706 - val_loss: 1.4219 - val_acc: 0.5300\n",
            "Epoch 39/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0617 - acc: 0.9761Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0567 - acc: 0.9784 - val_loss: 1.5553 - val_acc: 0.5300\n",
            "Epoch 40/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0731 - acc: 0.9760Epoch 1/200\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.0692 - acc: 0.9764 - val_loss: 1.3871 - val_acc: 0.5300\n",
            "Epoch 41/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0920 - acc: 0.9810Epoch 1/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0847 - acc: 0.9830 - val_loss: 1.9654 - val_acc: 0.5300\n",
            "Epoch 42/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0296 - acc: 0.9920Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0288 - acc: 0.9909 - val_loss: 1.8515 - val_acc: 0.5300\n",
            "Epoch 43/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0791 - acc: 0.9833Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0716 - acc: 0.9830 - val_loss: 2.1868 - val_acc: 0.5300\n",
            "Epoch 44/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0481 - acc: 0.9880Epoch 1/200\n",
            "11/11 [==============================] - 2s 175ms/step - loss: 0.0445 - acc: 0.9891 - val_loss: 1.9901 - val_acc: 0.5300\n",
            "Epoch 45/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0549 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0498 - acc: 0.9830 - val_loss: 2.1482 - val_acc: 0.5300\n",
            "Epoch 46/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0413 - acc: 0.9800Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0380 - acc: 0.9804 - val_loss: 1.3071 - val_acc: 0.5300\n",
            "Epoch 47/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1250 - acc: 0.9680Epoch 1/200\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.1277 - acc: 0.9673 - val_loss: 1.6829 - val_acc: 0.5300\n",
            "Epoch 48/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1206 - acc: 0.9696Epoch 1/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1130 - acc: 0.9706 - val_loss: 0.9061 - val_acc: 0.5300\n",
            "Epoch 49/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0184 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0172 - acc: 0.9902 - val_loss: 1.3142 - val_acc: 0.5300\n",
            "Epoch 50/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1432 - acc: 0.9761Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.1303 - acc: 0.9765 - val_loss: 0.8242 - val_acc: 0.4800\n",
            "Epoch 51/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1890 - acc: 0.9360Epoch 1/200\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.1775 - acc: 0.9400 - val_loss: 0.8728 - val_acc: 0.5200\n",
            "Epoch 52/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1210 - acc: 0.9714Epoch 1/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.1136 - acc: 0.9723 - val_loss: 0.7609 - val_acc: 0.4300\n",
            "Epoch 53/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0535 - acc: 0.9848Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0510 - acc: 0.9863 - val_loss: 0.8160 - val_acc: 0.4800\n",
            "Epoch 54/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0670 - acc: 0.9820Epoch 1/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.0613 - acc: 0.9824 - val_loss: 0.7699 - val_acc: 0.4200\n",
            "Epoch 55/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0406 - acc: 0.9840Epoch 1/200\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.0369 - acc: 0.9855 - val_loss: 0.7603 - val_acc: 0.4600\n",
            "Epoch 56/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0869 - acc: 0.9783Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0810 - acc: 0.9784 - val_loss: 0.7591 - val_acc: 0.5000\n",
            "Epoch 57/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0778 - acc: 0.9848Epoch 1/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.0741 - acc: 0.9843 - val_loss: 0.9944 - val_acc: 0.5300\n",
            "Epoch 58/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3306 - acc: 0.9833Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.2856 - acc: 0.9851 - val_loss: 1.1630 - val_acc: 0.5300\n",
            "Epoch 59/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0985 - acc: 0.9720Epoch 1/200\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.0969 - acc: 0.9709 - val_loss: 0.7602 - val_acc: 0.4500\n",
            "Epoch 60/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0612 - acc: 0.9804Epoch 1/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0719 - acc: 0.9784 - val_loss: 0.8553 - val_acc: 0.5200\n",
            "Epoch 61/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0834 - acc: 0.9780Epoch 1/200\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 0.0772 - acc: 0.9800 - val_loss: 0.8526 - val_acc: 0.5300\n",
            "Epoch 62/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0851 - acc: 0.9714Epoch 1/200\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.0783 - acc: 0.9745 - val_loss: 0.8044 - val_acc: 0.5200\n",
            "Epoch 63/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2413 - acc: 0.9957Epoch 1/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.2067 - acc: 0.9961 - val_loss: 1.1668 - val_acc: 0.5300\n",
            "Epoch 64/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0620 - acc: 0.9740Epoch 1/200\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.0564 - acc: 0.9764 - val_loss: 1.1524 - val_acc: 0.5300\n",
            "Epoch 65/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0442 - acc: 0.9857Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0589 - acc: 0.9830 - val_loss: 0.9789 - val_acc: 0.5200\n",
            "Epoch 66/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0846 - acc: 0.9804Epoch 1/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1217 - acc: 0.9765 - val_loss: 0.8500 - val_acc: 0.4400\n",
            "Epoch 67/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0594 - acc: 0.9860Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0609 - acc: 0.9855 - val_loss: 0.9209 - val_acc: 0.5200\n",
            "Epoch 68/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0490 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 0.0452 - acc: 0.9830 - val_loss: 1.1514 - val_acc: 0.4400\n",
            "Epoch 69/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0656 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0823 - acc: 0.9843 - val_loss: 0.8181 - val_acc: 0.4700\n",
            "Epoch 70/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0809 - acc: 0.9820Epoch 1/200\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.0797 - acc: 0.9818 - val_loss: 1.3263 - val_acc: 0.4700\n",
            "Epoch 71/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1678 - acc: 0.9696Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1537 - acc: 0.9706 - val_loss: 1.7844 - val_acc: 0.4700\n",
            "Epoch 72/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1290 - acc: 0.9717Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.1367 - acc: 0.9706 - val_loss: 0.9950 - val_acc: 0.4400\n",
            "Epoch 73/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0570 - acc: 0.9867Epoch 1/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0602 - acc: 0.9863 - val_loss: 1.0475 - val_acc: 0.4400\n",
            "Epoch 74/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0936 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.0837 - acc: 0.9824 - val_loss: 1.5779 - val_acc: 0.4700\n",
            "Epoch 75/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1393 - acc: 0.9761Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1275 - acc: 0.9784 - val_loss: 0.8498 - val_acc: 0.4700\n",
            "Epoch 76/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1320 - acc: 0.9760Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1229 - acc: 0.9764 - val_loss: 1.2820 - val_acc: 0.4500\n",
            "Epoch 77/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1551 - acc: 0.9652Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1573 - acc: 0.9667 - val_loss: 1.6259 - val_acc: 0.5300\n",
            "Epoch 78/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0793 - acc: 0.9739Epoch 1/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.1036 - acc: 0.9723 - val_loss: 0.8700 - val_acc: 0.4600\n",
            "Epoch 79/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0877 - acc: 0.9860Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0799 - acc: 0.9873 - val_loss: 2.0739 - val_acc: 0.5300\n",
            "Epoch 80/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0955 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0880 - acc: 0.9872 - val_loss: 1.5255 - val_acc: 0.5300\n",
            "Epoch 81/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0812 - acc: 0.9756Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0677 - acc: 0.9784 - val_loss: 2.1212 - val_acc: 0.5300\n",
            "Epoch 82/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0946 - acc: 0.9778Epoch 1/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0941 - acc: 0.9784 - val_loss: 1.4413 - val_acc: 0.5300\n",
            "Epoch 83/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0844 - acc: 0.9780Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0768 - acc: 0.9800 - val_loss: 1.2668 - val_acc: 0.5300\n",
            "Epoch 84/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0628 - acc: 0.9822Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0702 - acc: 0.9824 - val_loss: 0.9521 - val_acc: 0.5200\n",
            "Epoch 85/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0574 - acc: 0.9783Epoch 1/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0553 - acc: 0.9765 - val_loss: 1.7912 - val_acc: 0.5300\n",
            "Epoch 86/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0549 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0812 - acc: 0.9863 - val_loss: 2.3012 - val_acc: 0.5300\n",
            "Epoch 87/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0531 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0484 - acc: 0.9882 - val_loss: 1.7161 - val_acc: 0.5300\n",
            "Epoch 88/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0843 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0774 - acc: 0.9882 - val_loss: 1.7516 - val_acc: 0.5300\n",
            "Epoch 89/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0195 - acc: 0.9978Epoch 1/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0160 - acc: 0.9980 - val_loss: 2.1693 - val_acc: 0.5300\n",
            "Epoch 90/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0477 - acc: 0.9900Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0439 - acc: 0.9909 - val_loss: 1.7348 - val_acc: 0.5300\n",
            "Epoch 91/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2686 - acc: 0.9413Epoch 1/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.2438 - acc: 0.9426 - val_loss: 2.9053 - val_acc: 0.5300\n",
            "Epoch 92/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1107 - acc: 0.9700Epoch 1/200\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.1082 - acc: 0.9709 - val_loss: 1.3396 - val_acc: 0.5300\n",
            "Epoch 93/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2340 - acc: 0.9587Epoch 1/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.2980 - acc: 0.9553 - val_loss: 2.8110 - val_acc: 0.5300\n",
            "Epoch 94/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0771 - acc: 0.9800Epoch 1/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0734 - acc: 0.9800 - val_loss: 2.5775 - val_acc: 0.5300\n",
            "Epoch 95/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1748 - acc: 0.9674Epoch 1/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1713 - acc: 0.9667 - val_loss: 3.4117 - val_acc: 0.5300\n",
            "Epoch 96/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1089 - acc: 0.9717Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.1007 - acc: 0.9745 - val_loss: 1.7266 - val_acc: 0.5300\n",
            "Epoch 97/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1397 - acc: 0.9761Epoch 1/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.1301 - acc: 0.9765 - val_loss: 2.1694 - val_acc: 0.5300\n",
            "Epoch 98/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1548 - acc: 0.9696Epoch 1/200\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.1425 - acc: 0.9725 - val_loss: 1.3497 - val_acc: 0.5300\n",
            "Epoch 99/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0956 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1242 - acc: 0.9843 - val_loss: 2.6198 - val_acc: 0.5300\n",
            "Epoch 100/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0684 - acc: 0.9880Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1105 - acc: 0.9836 - val_loss: 2.1086 - val_acc: 0.5300\n",
            "Epoch 101/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0676 - acc: 0.9804Epoch 1/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0843 - acc: 0.9765 - val_loss: 2.3455 - val_acc: 0.5300\n",
            "Epoch 102/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0277 - acc: 0.9935Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0266 - acc: 0.9941 - val_loss: 2.1491 - val_acc: 0.5300\n",
            "Epoch 103/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0154 - acc: 0.9913Epoch 1/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0141 - acc: 0.9922 - val_loss: 2.1346 - val_acc: 0.5300\n",
            "Epoch 104/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0794 - acc: 0.9738Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0732 - acc: 0.9766 - val_loss: 2.3036 - val_acc: 0.5300\n",
            "Epoch 105/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0314 - acc: 0.9900Epoch 1/200\n",
            "11/11 [==============================] - 2s 175ms/step - loss: 0.0312 - acc: 0.9891 - val_loss: 3.1855 - val_acc: 0.5300\n",
            "Epoch 106/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0307 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 0.0325 - acc: 0.9882 - val_loss: 3.1614 - val_acc: 0.5300\n",
            "Epoch 107/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0022 - acc: 1.0000Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 2.9995 - val_acc: 0.5300\n",
            "Epoch 108/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0456 - acc: 0.9800Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0417 - acc: 0.9804 - val_loss: 3.3298 - val_acc: 0.5300\n",
            "Epoch 109/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0208 - acc: 0.9978Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0435 - acc: 0.9961 - val_loss: 2.7351 - val_acc: 0.5300\n",
            "Epoch 110/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0291 - acc: 0.9957Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0272 - acc: 0.9961 - val_loss: 2.7573 - val_acc: 0.5300\n",
            "Epoch 111/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0433 - acc: 0.9880Epoch 1/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0394 - acc: 0.9891 - val_loss: 3.6656 - val_acc: 0.5300\n",
            "Epoch 112/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0175 - acc: 0.9929Epoch 1/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0195 - acc: 0.9915 - val_loss: 2.2539 - val_acc: 0.5300\n",
            "Epoch 113/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0574 - acc: 0.9800Epoch 1/200\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.0553 - acc: 0.9782 - val_loss: 2.1709 - val_acc: 0.5300\n",
            "Epoch 114/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0649 - acc: 0.9848Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0593 - acc: 0.9863 - val_loss: 2.3731 - val_acc: 0.5300\n",
            "Epoch 115/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0145 - acc: 0.9935Epoch 1/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0167 - acc: 0.9922 - val_loss: 2.0121 - val_acc: 0.5300\n",
            "Epoch 116/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2263 - acc: 0.9857Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.2033 - acc: 0.9851 - val_loss: 1.2420 - val_acc: 0.5200\n",
            "Epoch 117/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0981 - acc: 0.9820Epoch 1/200\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0892 - acc: 0.9836 - val_loss: 2.4591 - val_acc: 0.5300\n",
            "Epoch 118/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0133 - acc: 0.9935Epoch 1/200\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0377 - acc: 0.9902 - val_loss: 3.5025 - val_acc: 0.5300\n",
            "Epoch 119/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0449 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0461 - acc: 0.9882 - val_loss: 2.1620 - val_acc: 0.5300\n",
            "Epoch 120/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1094 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.1058 - acc: 0.9824 - val_loss: 2.6212 - val_acc: 0.5300\n",
            "Epoch 121/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0589 - acc: 0.9848Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0541 - acc: 0.9863 - val_loss: 2.5687 - val_acc: 0.5300\n",
            "Epoch 122/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1589 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.1413 - acc: 0.9863 - val_loss: 3.5311 - val_acc: 0.5300\n",
            "Epoch 123/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1285 - acc: 0.9717Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1173 - acc: 0.9745 - val_loss: 2.4719 - val_acc: 0.5300\n",
            "Epoch 124/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0863 - acc: 0.9804Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0802 - acc: 0.9824 - val_loss: 1.9164 - val_acc: 0.5300\n",
            "Epoch 125/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0583 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0538 - acc: 0.9882 - val_loss: 3.1246 - val_acc: 0.5300\n",
            "Epoch 126/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0050 - acc: 0.9978Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0239 - acc: 0.9941 - val_loss: 3.3662 - val_acc: 0.5300\n",
            "Epoch 127/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0223 - acc: 0.9920Epoch 1/200\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.0254 - acc: 0.9891 - val_loss: 2.8592 - val_acc: 0.5300\n",
            "Epoch 128/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2158 - acc: 0.9674Epoch 1/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.1991 - acc: 0.9686 - val_loss: 4.5878 - val_acc: 0.5300\n",
            "Epoch 129/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0515 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 0.0475 - acc: 0.9830 - val_loss: 3.8466 - val_acc: 0.5300\n",
            "Epoch 130/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0995 - acc: 0.9820Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0905 - acc: 0.9836 - val_loss: 5.0460 - val_acc: 0.5300\n",
            "Epoch 131/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0347 - acc: 0.9913Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0484 - acc: 0.9902 - val_loss: 4.4274 - val_acc: 0.5300\n",
            "Epoch 132/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0217 - acc: 0.9935Epoch 1/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.0199 - acc: 0.9941 - val_loss: 4.3045 - val_acc: 0.5300\n",
            "Epoch 133/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0750 - acc: 0.9900Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0682 - acc: 0.9909 - val_loss: 4.6294 - val_acc: 0.5300\n",
            "Epoch 134/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0684 - acc: 0.9810Epoch 1/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.0631 - acc: 0.9830 - val_loss: 3.9643 - val_acc: 0.5300\n",
            "Epoch 135/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1002 - acc: 0.9848Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1018 - acc: 0.9843 - val_loss: 3.7872 - val_acc: 0.5300\n",
            "Epoch 136/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0122 - acc: 0.9978Epoch 1/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0112 - acc: 0.9980 - val_loss: 3.1535 - val_acc: 0.5300\n",
            "Epoch 137/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0551 - acc: 0.9900Epoch 1/200\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.0527 - acc: 0.9891 - val_loss: 3.6343 - val_acc: 0.5300\n",
            "Epoch 138/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0607 - acc: 0.9881Epoch 1/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0575 - acc: 0.9872 - val_loss: 3.9464 - val_acc: 0.5300\n",
            "Epoch 139/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0521 - acc: 0.9880Epoch 1/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0476 - acc: 0.9891 - val_loss: 3.4060 - val_acc: 0.5300\n",
            "Epoch 140/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0615 - acc: 0.9952Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0537 - acc: 0.9957 - val_loss: 3.5696 - val_acc: 0.5300\n",
            "Epoch 141/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0524 - acc: 0.9840Epoch 1/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0485 - acc: 0.9855 - val_loss: 4.4167 - val_acc: 0.5300\n",
            "Epoch 142/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0509 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0466 - acc: 0.9882 - val_loss: 3.6314 - val_acc: 0.5300\n",
            "Epoch 143/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1072 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.1000 - acc: 0.9872 - val_loss: 4.1692 - val_acc: 0.5300\n",
            "Epoch 144/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0369 - acc: 0.9960Epoch 1/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0336 - acc: 0.9964 - val_loss: 4.3643 - val_acc: 0.5300\n",
            "Epoch 145/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1358 - acc: 0.9761Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.1243 - acc: 0.9784 - val_loss: 2.6556 - val_acc: 0.5300\n",
            "Epoch 146/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2968 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.2536 - acc: 0.9902 - val_loss: 2.1172 - val_acc: 0.5300\n",
            "Epoch 147/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1892 - acc: 0.9700Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1873 - acc: 0.9686 - val_loss: 3.4692 - val_acc: 0.5300\n",
            "Epoch 148/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0892 - acc: 0.9840Epoch 1/200\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.0868 - acc: 0.9836 - val_loss: 2.4392 - val_acc: 0.5300\n",
            "Epoch 149/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0700 - acc: 0.9905Epoch 1/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0743 - acc: 0.9894 - val_loss: 2.6940 - val_acc: 0.5300\n",
            "Epoch 150/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1578 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.1371 - acc: 0.9843 - val_loss: 2.0910 - val_acc: 0.5300\n",
            "Epoch 151/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0775 - acc: 0.9844Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0647 - acc: 0.9863 - val_loss: 1.3069 - val_acc: 0.5300\n",
            "Epoch 152/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0995 - acc: 0.9720Epoch 1/200\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.0904 - acc: 0.9745 - val_loss: 2.8672 - val_acc: 0.5300\n",
            "Epoch 153/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1882 - acc: 0.9783Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1954 - acc: 0.9745 - val_loss: 1.5965 - val_acc: 0.5300\n",
            "Epoch 154/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0355 - acc: 0.9935Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0325 - acc: 0.9941 - val_loss: 2.0341 - val_acc: 0.5300\n",
            "Epoch 155/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0873 - acc: 0.9844Epoch 1/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0719 - acc: 0.9863 - val_loss: 2.7643 - val_acc: 0.5300\n",
            "Epoch 156/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1588 - acc: 0.9848Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1480 - acc: 0.9843 - val_loss: 2.0455 - val_acc: 0.5300\n",
            "Epoch 157/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0303 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0327 - acc: 0.9882 - val_loss: 1.9828 - val_acc: 0.5300\n",
            "Epoch 158/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0301 - acc: 0.9900Epoch 1/200\n",
            "11/11 [==============================] - 2s 177ms/step - loss: 0.0276 - acc: 0.9909 - val_loss: 2.1703 - val_acc: 0.5300\n",
            "Epoch 159/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0771 - acc: 0.9857Epoch 1/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0683 - acc: 0.9872 - val_loss: 3.4892 - val_acc: 0.5300\n",
            "Epoch 160/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1833 - acc: 0.9804Epoch 1/200\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.1594 - acc: 0.9824 - val_loss: 1.5839 - val_acc: 0.5300\n",
            "Epoch 161/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1942 - acc: 0.9739Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.1735 - acc: 0.9765 - val_loss: 3.4256 - val_acc: 0.5300\n",
            "Epoch 162/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0915 - acc: 0.9783Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0833 - acc: 0.9804 - val_loss: 2.8518 - val_acc: 0.5300\n",
            "Epoch 163/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1532 - acc: 0.9780Epoch 1/200\n",
            "11/11 [==============================] - 2s 179ms/step - loss: 0.1521 - acc: 0.9764 - val_loss: 1.9791 - val_acc: 0.5300\n",
            "Epoch 164/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0043 - acc: 0.9952Epoch 1/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0044 - acc: 0.9957 - val_loss: 1.6812 - val_acc: 0.5300\n",
            "Epoch 165/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0425 - acc: 0.9940Epoch 1/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.1051 - acc: 0.9902 - val_loss: 1.3816 - val_acc: 0.5200\n",
            "Epoch 166/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0576 - acc: 0.9840Epoch 1/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.0525 - acc: 0.9855 - val_loss: 2.3404 - val_acc: 0.5300\n",
            "Epoch 167/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2672 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.2348 - acc: 0.9863 - val_loss: 1.6663 - val_acc: 0.5300\n",
            "Epoch 168/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2741 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.2373 - acc: 0.9843 - val_loss: 3.4387 - val_acc: 0.5300\n",
            "Epoch 169/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2087 - acc: 0.9674Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.1896 - acc: 0.9706 - val_loss: 1.4940 - val_acc: 0.5200\n",
            "Epoch 170/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0922 - acc: 0.9804Epoch 1/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.1026 - acc: 0.9804 - val_loss: 1.3476 - val_acc: 0.5200\n",
            "Epoch 171/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0474 - acc: 0.9860Epoch 1/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0480 - acc: 0.9836 - val_loss: 1.8234 - val_acc: 0.5300\n",
            "Epoch 172/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0853 - acc: 0.9826Epoch 1/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0992 - acc: 0.9804 - val_loss: 1.9864 - val_acc: 0.5300\n",
            "Epoch 173/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0560 - acc: 0.9854Epoch 1/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.0494 - acc: 0.9872 - val_loss: 3.0838 - val_acc: 0.5300\n",
            "Epoch 174/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1124 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0981 - acc: 0.9902 - val_loss: 1.9876 - val_acc: 0.5300\n",
            "Epoch 175/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0490 - acc: 0.9860Epoch 1/200\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.0445 - acc: 0.9873 - val_loss: 2.4755 - val_acc: 0.5300\n",
            "Epoch 176/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0284 - acc: 0.9857Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0360 - acc: 0.9830 - val_loss: 2.7974 - val_acc: 0.5300\n",
            "Epoch 177/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0496 - acc: 0.9860Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0570 - acc: 0.9855 - val_loss: 2.4601 - val_acc: 0.5300\n",
            "Epoch 178/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0202 - acc: 0.9902Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0316 - acc: 0.9894 - val_loss: 3.3788 - val_acc: 0.5300\n",
            "Epoch 179/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0473 - acc: 0.9940Epoch 1/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0430 - acc: 0.9945 - val_loss: 3.8520 - val_acc: 0.5300\n",
            "Epoch 180/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0091 - acc: 0.9956Epoch 1/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0079 - acc: 0.9961 - val_loss: 3.1458 - val_acc: 0.5300\n",
            "Epoch 181/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0315 - acc: 0.9913Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0364 - acc: 0.9902 - val_loss: 3.5777 - val_acc: 0.5300\n",
            "Epoch 182/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0585 - acc: 0.9913Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0968 - acc: 0.9882 - val_loss: 2.7831 - val_acc: 0.5300\n",
            "Epoch 183/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0259 - acc: 0.9880Epoch 1/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 0.0236 - acc: 0.9891 - val_loss: 3.4848 - val_acc: 0.5300\n",
            "Epoch 184/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0289 - acc: 0.9929Epoch 1/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0267 - acc: 0.9936 - val_loss: 2.8956 - val_acc: 0.5300\n",
            "Epoch 185/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0800 - acc: 0.9870Epoch 1/200\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.0731 - acc: 0.9882 - val_loss: 2.6100 - val_acc: 0.5300\n",
            "Epoch 186/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0346 - acc: 0.9940Epoch 1/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0314 - acc: 0.9945 - val_loss: 1.8834 - val_acc: 0.5300\n",
            "Epoch 187/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0652 - acc: 0.9935Epoch 1/200\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.0594 - acc: 0.9941 - val_loss: 2.7179 - val_acc: 0.5300\n",
            "Epoch 188/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0050 - acc: 0.9980 - val_loss: 3.0089 - val_acc: 0.5300\n",
            "Epoch 189/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0503 - acc: 0.9848Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0464 - acc: 0.9851 - val_loss: 2.0731 - val_acc: 0.5300\n",
            "Epoch 190/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0670 - acc: 0.9860Epoch 1/200\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.0609 - acc: 0.9873 - val_loss: 1.4826 - val_acc: 0.5200\n",
            "Epoch 191/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0419 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0383 - acc: 0.9902 - val_loss: 1.9871 - val_acc: 0.5300\n",
            "Epoch 192/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0547 - acc: 0.9891Epoch 1/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0910 - acc: 0.9863 - val_loss: 2.5753 - val_acc: 0.5300\n",
            "Epoch 193/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0149 - acc: 0.9940Epoch 1/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0142 - acc: 0.9945 - val_loss: 1.2196 - val_acc: 0.5300\n",
            "Epoch 194/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.1367 - acc: 0.9762Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.2005 - acc: 0.9745 - val_loss: 2.9797 - val_acc: 0.5300\n",
            "Epoch 195/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0411 - acc: 0.9900Epoch 1/200\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.0375 - acc: 0.9909 - val_loss: 0.9078 - val_acc: 0.5100\n",
            "Epoch 196/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.0746 - acc: 0.9756Epoch 1/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0616 - acc: 0.9787 - val_loss: 1.7522 - val_acc: 0.5300\n",
            "Epoch 197/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0631 - acc: 0.9920Epoch 1/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0650 - acc: 0.9922 - val_loss: 1.8536 - val_acc: 0.5300\n",
            "Epoch 198/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0964 - acc: 0.9860Epoch 1/200\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.1243 - acc: 0.9836 - val_loss: 0.9382 - val_acc: 0.5100\n",
            "Epoch 199/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0711 - acc: 0.9786Epoch 1/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0653 - acc: 0.9809 - val_loss: 1.1750 - val_acc: 0.5000\n",
            "Epoch 200/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.0224 - acc: 0.9920Epoch 1/200\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.0236 - acc: 0.9909 - val_loss: 1.8012 - val_acc: 0.5300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4960f9c978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VngeUBIdyJ1T",
        "outputId": "9baaf2a3-9173-405a-d9ca-2ec187199863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "#img_path = '/content/drive/My Drive/Colab Notebooks/data/validation/class1/1_67_3043537.jpg'\n",
        "#img_path = '/content/drive/My Drive/Colab Notebooks/data/validation/class2/2_88_81794.jpg'\n",
        "img_path = '/content/drive/My Drive/Colab Notebooks/data/validation/class2/2_114_4057001.jpg'\n",
        "img = image.load_img(img_path, target_size=(80, 80))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "preds = np.argmax(preds, axis=-1)\n",
        "print(preds)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "#print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8bbbf5b50e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#img_path = '/content/drive/My Drive/Colab Notebooks/data/validation/class2/2_88_81794.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Colab Notebooks/data/validation/class2/2_114_4057001.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/data/validation/class2/2_114_4057001.jpg'"
          ]
        }
      ]
    }
  ]
}